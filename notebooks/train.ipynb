{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e659859-f060-4b22-bd85-7ca5cbdf5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb9a6a45-1811-41ed-baa9-5e66356bf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")\n",
    "#os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6b2b6a-a0b0-444d-b106-a0a1677bcbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hz/m3d-vton/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caad485c-0b93-4321-b3aa-5740799d9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec93117-cb87-43bb-82e4-9cec81646d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataroot DATAROOT] [--datamode DATAMODE]\n",
      "                             [--datalist DATALIST] [--name NAME]\n",
      "                             [--suffix SUFFIX] [--gpu_ids GPU_IDS]\n",
      "                             [--checkpoints_dir CHECKPOINTS_DIR]\n",
      "                             [--model MODEL] [--ngf NGF] [--netD NETD]\n",
      "                             [--ndf NDF] [--n_layers_D N_LAYERS_D]\n",
      "                             [--norm NORM] [--init_type INIT_TYPE]\n",
      "                             [--init_gain INIT_GAIN] [--use_dropout]\n",
      "                             [--max_dataset_size MAX_DATASET_SIZE]\n",
      "                             [--img_height IMG_HEIGHT] [--img_width IMG_WIDTH]\n",
      "                             [--batch_size BATCH_SIZE] [--serial_batches]\n",
      "                             [--num_threads NUM_THREADS] [--no_pin_memory]\n",
      "                             [--epoch EPOCH] [--load_iter LOAD_ITER]\n",
      "                             [--display_winsize DISPLAY_WINSIZE] [--verbose]\n",
      "                             [--no_tensorboard] [--print_freq PRINT_FREQ]\n",
      "                             [--display_epoch_freq DISPLAY_EPOCH_FREQ]\n",
      "                             [--display_ncols DISPLAY_NCOLS]\n",
      "                             [--save_latest_freq SAVE_LATEST_FREQ]\n",
      "                             [--save_epoch_freq SAVE_EPOCH_FREQ]\n",
      "                             [--save_by_iter] [--continue_train]\n",
      "                             [--epoch_count EPOCH_COUNT] [--phase PHASE]\n",
      "                             [--n_epochs_keep N_EPOCHS_KEEP]\n",
      "                             [--n_epochs_decay N_EPOCHS_DECAY] [--lr LR]\n",
      "                             [--gan_mode GAN_MODE] [--pool_size POOL_SIZE]\n",
      "                             [--lr_policy LR_POLICY]\n",
      "                             [--lr_decay_iters LR_DECAY_ITERS] [--add_tps]\n",
      "                             [--add_depth] [--add_segmt]\n",
      "                             [--grid_size GRID_SIZE] [--input_nc_A INPUT_NC_A]\n",
      "                             [--input_nc_B INPUT_NC_B]\n",
      "                             [--n_layers_feat_extract N_LAYERS_FEAT_EXTRACT]\n",
      "                             [--add_theta_loss] [--add_grid_loss]\n",
      "                             [--lambda_depth LAMBDA_DEPTH]\n",
      "                             [--lambda_segmt LAMBDA_SEGMT]\n",
      "                             [--lambda_warp LAMBDA_WARP]\n",
      "                             [--lambda_theta LAMBDA_THETA]\n",
      "                             [--lambda_grid LAMBDA_GRID] [--radius RADIUS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/hz/.local/share/jupyter/runtime/kernel-6725ff41-c7a7-4049-8e18-53c9a4b66bed.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/anaconda3/envs/comp6381/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e104f-cdc5-4199-bae6-359ef59d041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.name = \"TFM\"\n",
    "opt.dataroot = \"../datasets/MPV3D/\"\n",
    "opt.warproot = \"outs/mtm_results/aligned/MTM/train_pairs\"\n",
    "opt.datalist = \"train_pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096207b-b7bd-458c-9cb5-73e8b79912b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.model = \"TFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3be904-4a08-4a1c-a22a-9e4251f07cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08eb16-5ce9-428d-b1df-40adcf48cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)    # get the number of images in the dataset.\n",
    "print('The number of training images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a536f23-99ac-4b2b-8b55-48ad27f09db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d1484-03b6-4914-8e1d-23ea48561d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d146e-442c-4206-8b15-240e9e12c94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc6906-4055-47fc-a423-0004f8e7bb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff528f18-e292-4e5e-bd25-eb7a947141a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96396944-b1dc-40e7-9c3d-3c428b68cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603d58f-4b18-4a7d-81b9-58082831c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the submodule with skip connection.\n",
    "    X -------------------identity---------------------- X\n",
    "      |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.InstanceNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet submodule with skip connections.\n",
    "\n",
    "        Parameters:\n",
    "            outer_nc (int) -- the number of filters in the outer conv layer\n",
    "            inner_nc (int) -- the number of filters in the inner conv layer\n",
    "            input_nc (int) -- the number of channels in input images/features\n",
    "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
    "            outermost (bool)    -- if this module is the outermost module\n",
    "            innermost (bool)    -- if this module is the innermost module\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "        \"\"\"\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            upconv = nn.Conv2d(inner_nc * 2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upsample, upconv]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            upconv = nn.Conv2d(inner_nc, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upsample, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            upconv = nn.Conv2d(inner_nc*2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upsample, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "        \n",
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Defines the Unet generator.\"\"\"\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet generator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
    "                                image of size 128x128 will become of size 1x1 at the bottleneck\n",
    "            ngf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "\n",
    "        We construct the U-Net from the innermost layer to the outermost layer.\n",
    "        It is a recursive process.\n",
    "        \"\"\"\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True) # add the innermost layer\n",
    "        for i in range(num_downs - 5): # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310e680-b896-47e0-b493-3e051fcdb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1, 9, 256, 192))\n",
    "model = None\n",
    "model = UnetGenerator(input_nc=9, output_nc=4, num_downs=6)\n",
    "y = model.forward(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43019ab-db2a-445f-b334-7ee20e591503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091bd83-557a-4f34-a372-ae6d51c24f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6ba0c-1f71-44fd-9bbe-5c53d076d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features=64, norm_layer=nn.BatchNorm2d):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "        if norm_layer == None:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                norm_layer(in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_features, in_features, 3, 1, 1, bias=False),\n",
    "                norm_layer(in_features)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResUnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the submodule with skip connection.\n",
    "    X -------------------identity---------------------- X\n",
    "      |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(ResUnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=3,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        # add two resblock\n",
    "        res_downconv = [ResidualBlock(inner_nc, norm_layer), ResidualBlock(inner_nc, norm_layer)]\n",
    "        res_upconv = [ResidualBlock(outer_nc, norm_layer), ResidualBlock(outer_nc, norm_layer)]\n",
    "\n",
    "        downrelu = nn.ReLU(True)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        if norm_layer != None:\n",
    "            downnorm = norm_layer(inner_nc)\n",
    "            upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc * 2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv, downrelu] + res_downconv\n",
    "            up = [upsample, upconv]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv, downrelu] + res_downconv\n",
    "            if norm_layer == None:\n",
    "                up = [upsample, upconv, uprelu] + res_upconv\n",
    "            else:\n",
    "                up = [upsample, upconv, upnorm, uprelu] + res_upconv\n",
    "            model = down + up\n",
    "        else:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            upconv = nn.Conv2d(inner_nc*2, outer_nc, kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            if norm_layer == None:\n",
    "                down = [downconv, downrelu] + res_downconv\n",
    "                up = [upsample, upconv, uprelu] + res_upconv\n",
    "            else:\n",
    "                down = [downconv, downnorm, downrelu] + res_downconv\n",
    "                up = [upsample, upconv, upnorm, uprelu] + res_upconv\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "        \n",
    "        \n",
    "class ResUnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_downs=5, ngf=32,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(ResUnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
    "\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = ResUnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = ResUnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "        \n",
    "        self.model = unet_block\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129ee59-10a9-4bb0-b7de-c1ec31eb562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1, 9, 256, 192))\n",
    "model = None\n",
    "model = ResUnetGenerator(input_nc=9, output_nc=4, num_downs=6)\n",
    "y = model.forward(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146ae64-cb51-4a55-91db-cdeff1e2f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52c706-113c-411e-9827-3554409240cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
