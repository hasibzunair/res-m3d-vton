{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c54cff0-25a8-46a9-99e3-8612e8490f1e",
   "metadata": {},
   "source": [
    "### Test model\n",
    "\n",
    "Not working now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ddd7f4-bde7-4e87-b5e1-2d31dbe8eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0e977-1232-424c-9654-a21ccf144690",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5f638-c0ee-494f-8858-58475c2f2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b24f6-417a-475f-b91c-dd55ce1f6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from options.test_options import TestOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.util import tensor2im, save_image, save_depth, decode_labels, depth2normal_ortho\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90bdc5-e25e-4f4e-8fce-d79fd373ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to models\n",
    "exp_name = \"exp1\"\n",
    "models_dir = os.path.join(\"../logs\", exp_name)\n",
    "models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfdeae-afa7-478b-b489-0a6069fe26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TestOptions().parse()  # get test options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adbc22-bad7-4cf5-978a-922bd6fcc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.checkpoints_dir = models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff0576-681f-4c12-ae57-c1b206b6b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make destination dirs.\n",
    "results_dir = os.path.join(\"../\", opt.results_dir, exp_name, opt.datamode, opt.name, opt.datalist)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7caec-a009-4a9a-9dff-e0eee4229a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(results_dir, 'warp-cloth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'warp-mask'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'warp-grid'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'warp-cloth-sobel'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'segmt'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'segmt-vis'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'initial-depth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'initial-depth-vis'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'initial-normal-vis'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bcfa5-c223-4db2-b649-86e65a80cf58",
   "metadata": {},
   "source": [
    "## Test data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb1053-6cd7-4053-a262-74e9c7ac34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.dataroot = \"../mpv3d_example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a43d2-2218-4b8a-a830-1a8c71bc0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77fe5c-579a-4bad-a919-fad705c4fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-code some parameters for test\n",
    "opt.num_threads = 1   # test code only supports num_threads = 1\n",
    "opt.batch_size = 1    # test code only supports batch_size = 1\n",
    "opt.serial_batches = True     # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "dataset = create_dataset(opt) # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)\n",
    "model = create_model(opt)     # create a model given opt.model and other options\n",
    "model.setup(opt)              # regular setup: load and print networks\n",
    "\n",
    "# test with eval mode. This only affects layers like batchnorm and dropout.\n",
    "if opt.eval:\n",
    "    model.eval()\n",
    "    \n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.num_test:   # only apply our model to opt.num_test images.\n",
    "        break\n",
    "    model.set_input(data)   # unpack data from data loader\n",
    "    model.test()            # run inference\n",
    "    im_name = model.im_name[0] # get person name\n",
    "    c_name = model.c_name[0]   # get cloth name\n",
    "    # visuals = model.get_current_visuals()  # get image results\n",
    "    print('processing (%04d)-th / (%04d) image...' % (i+1, dataset_size), end='\\r')\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # save warped_cloth, warped_cloth_mask, warp_grid, roi_segmt and roi_depth to disk\n",
    "    if opt.add_tps:\n",
    "        warped_cloth = tensor2im(model.warped_cloth)\n",
    "        warped_grid = tensor2im(model.tps_grid)\n",
    "        save_image(warped_cloth, os.path.join(results_dir, 'warp-cloth', c_name))\n",
    "        save_image(model.warped_cloth_mask.mul(255).squeeze(0).squeeze(0).cpu().numpy().astype(np.uint8), os.path.join(results_dir, 'warp-mask', c_name.replace('.jpg','_mask.jpg')))\n",
    "        save_image(warped_grid, os.path.join(results_dir, 'warp-grid', c_name.replace('.jpg','_grid.jpg')))\n",
    "        # save cloth sobel\n",
    "        warped_cloth_gray = cv2.cvtColor(warped_cloth,cv2.COLOR_RGB2GRAY)\n",
    "        warped_cloth_sobelx = cv2.Sobel(warped_cloth_gray,cv2.CV_64F,1,0,ksize=5)\n",
    "        warped_cloth_sobely = cv2.Sobel(warped_cloth_gray,cv2.CV_64F,0,1,ksize=5)\n",
    "        plt.imsave(os.path.join(results_dir, 'warp-cloth-sobel', c_name.replace('.jpg', '_sobelx.png')), warped_cloth_sobelx, cmap='gray')\n",
    "        plt.imsave(os.path.join(results_dir, 'warp-cloth-sobel', c_name.replace('.jpg', '_sobely.png')), warped_cloth_sobely, cmap='gray')\n",
    "    if opt.add_depth:\n",
    "        fdepth_pred = model.fdepth_pred.squeeze(0).squeeze(0).cpu().float().numpy()\n",
    "        bdepth_pred = model.bdepth_pred.squeeze(0).squeeze(0).cpu().float().numpy()\n",
    "        save_depth(fdepth_pred, os.path.join(results_dir, 'initial-depth', im_name.replace('whole_front.png', 'initial_front_depth.npy')))\n",
    "        save_depth(bdepth_pred, os.path.join(results_dir, 'initial-depth', im_name.replace('whole_front.png', 'initial_back_depth.npy')))\n",
    "        if opt.save_depth_vis:\n",
    "            fdepth_pred_vis = (fdepth_pred + 1) / 2.0 * 255.0\n",
    "            bdepth_pred_vis = (bdepth_pred + 1) / 2.0 * 255.0\n",
    "            save_image(fdepth_pred_vis.astype(np.uint8), os.path.join(results_dir, 'initial-depth-vis', im_name.replace('whole_front.png', 'initial_front_depth.png')))\n",
    "            save_image(bdepth_pred_vis.astype(np.uint8), os.path.join(results_dir, 'initial-depth-vis', im_name.replace('whole_front.png', 'initial_back_depth.png')))\n",
    "        if opt.save_normal_vis:\n",
    "            fnormal_pred = depth2normal_ortho(model.fdepth_pred).squeeze(0)\n",
    "            fnormal_np = fnormal_pred.permute(1,2,0).cpu().numpy()\n",
    "            fnormal_vis = fnormal_np * 0.5 + 0.5\n",
    "            fnormal_vis = (fnormal_vis * 255).astype(np.uint8)\n",
    "            fnormal_pil = Image.fromarray(fnormal_vis)\n",
    "            fnormal_pil.save(os.path.join(results_dir, 'initial-normal-vis', im_name.replace('.png','_normal.png')))\n",
    "            bnormal_pred = depth2normal_ortho(model.bdepth_pred).squeeze(0)\n",
    "            bnormal_np = bnormal_pred.permute(1,2,0).cpu().numpy()\n",
    "            bnormal_vis = bnormal_np * 0.5 + 0.5\n",
    "            bnormal_vis = (bnormal_vis * 255).astype(np.uint8)\n",
    "            bnormal_pil = Image.fromarray(bnormal_vis)\n",
    "            bnormal_pil.save(os.path.join(results_dir, 'initial-normal-vis', im_name.replace('front.png','back_normal.png')))\n",
    "    if opt.add_segmt:\n",
    "        save_image(model.segmt_pred_argmax.squeeze(0).squeeze(0).cpu().numpy().astype(np.uint8), os.path.join(results_dir, 'segmt', im_name.replace('front.png', 'segmt.png')))\n",
    "        if opt.save_segmt_vis: # WARNING: very slow\n",
    "            save_image(tensor2im(decode_labels(model.segmt_pred_argmax)), os.path.join(results_dir, 'segmt-vis', im_name.replace('front.png', 'segmt_vis.png')))\n",
    "            \n",
    "print(f'\\nTest {opt.model} down.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55204656-e328-4e4b-911b-94eba568c775",
   "metadata": {},
   "source": [
    "## Predict DRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fc79d-8fee-40ee-8336-9d8c83040555",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(results_dir, 'final-depth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'final-depth-vis'), exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, 'final-normal-vis'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8be1a8-f260-46b9-8085-8e33b53214fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.model = \"DRM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001256c5-b5be-4279-8888-8339c0d6438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt.warproot = models_dir + \"/aligned/MTM/test_pairs\"\n",
    "#opt.warproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf6f6d-ad79-4a91-b36c-11d82999136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-code some parameters for test\n",
    "opt.num_threads = 1   # test code only supports num_threads = 1\n",
    "opt.batch_size = 1    # test code only supports batch_size = 1\n",
    "opt.serial_batches = True     # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "dataset = create_dataset(opt) # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)\n",
    "model = create_model(opt)     # create a model given opt.model and other options\n",
    "model.setup(opt)              # regular setup: load and print networks\n",
    "\n",
    "# test with eval mode. This only affects layers like batchnorm and dropout.\n",
    "if opt.eval:\n",
    "    model.eval()\n",
    "    \n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.num_test:   # only apply our model to opt.num_test images.\n",
    "        break\n",
    "    model.set_input(data)   # unpack data from data loader\n",
    "    model.test()            # run inference\n",
    "    im_name = model.im_name[0] # get person name\n",
    "    c_name = model.c_name[0]   # get cloth name\n",
    "    # visuals = model.get_current_visuals()  # get image results\n",
    "    print('processing (%04d)-th / (%04d) image...' % (i+1, dataset_size), end='\\r')\n",
    "    time.sleep(0.001)\n",
    "\n",
    "    # save refined depth to disk\n",
    "    imfd_pred = model.imfd_pred.squeeze(0).squeeze(0).cpu().float().numpy()\n",
    "    imbd_pred = model.imbd_pred.squeeze(0).squeeze(0).cpu().float().numpy()\n",
    "    save_depth(imfd_pred, os.path.join(results_dir, 'final-depth', im_name.replace('.png','_depth.npy')))\n",
    "    save_depth(imbd_pred, os.path.join(results_dir, 'final-depth', im_name.replace('front.png','back_depth.npy')))\n",
    "    if opt.save_depth_vis:\n",
    "        imfd_pred_vis = (imfd_pred + 1) / 2.0 * 255.0\n",
    "        imbd_pred_vis = (imbd_pred + 1) / 2.0 * 255.0\n",
    "        save_image(imfd_pred_vis.astype(np.uint8), os.path.join(results_dir, 'final-depth-vis', im_name.replace('.png', '_depth.png')))\n",
    "        save_image(imbd_pred_vis.astype(np.uint8), os.path.join(results_dir, 'final-depth-vis', im_name.replace('front.png', 'back_depth.png')))\n",
    "    if opt.save_normal_vis:\n",
    "        fnormal_pred = depth2normal_ortho(model.imfd_pred).squeeze(0)\n",
    "        fnormal_np = fnormal_pred.permute(1,2,0).cpu().numpy()\n",
    "        fnormal_vis = fnormal_np * 0.5 + 0.5\n",
    "        fnormal_vis = (fnormal_vis * 255).astype(np.uint8)\n",
    "        fnormal_pil = Image.fromarray(fnormal_vis)\n",
    "        fnormal_pil.save(os.path.join(results_dir, 'final-normal-vis', im_name.replace('.png','_normal.png')))\n",
    "        bnormal_pred = depth2normal_ortho(model.imbd_pred).squeeze(0)\n",
    "        bnormal_np = bnormal_pred.permute(1,2,0).cpu().numpy()\n",
    "        bnormal_vis = bnormal_np * 0.5 + 0.5\n",
    "        bnormal_vis = (bnormal_vis * 255).astype(np.uint8)\n",
    "        bnormal_pil = Image.fromarray(bnormal_vis)\n",
    "        bnormal_pil.save(os.path.join(results_dir, 'final-normal-vis', im_name.replace('front.png','back_normal.png')))\n",
    "\n",
    "print(f'\\nTest {opt.model} down.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fe493-8d0d-4806-894b-a558a48a6d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
